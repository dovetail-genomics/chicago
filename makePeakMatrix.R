#! /usr/bin/env Rscript
message("***makePeakMatrix.R***\n")

library(argparser)

if (packageVersion("argparser") < 0.3) {
  stop("argparser version (", packageVersion("argparser"), ") is out of date - 0.3 or later is required. Please open R and run install.packages('argparser') to update.")
}

### A great function from http://www.r-bloggers.com/testing-for-valid-variable-names/
is_valid_variable_name = function(x, allow_reserved = TRUE, unique = FALSE)
{
  ok = TRUE
  max_name_length <- if(getRversion() < "2.13.0") 256L else 10000L
  if(!allow_reserved){
    ok[x == "..."] <- FALSE
    ok[grepl("^\\.{2}[[:digit:]]+$", x)] <- FALSE
  }
  ok[x != make.names(x, unique = unique)] <- FALSE
  ok
}

loadFromRDa = function(f, var){
  this = environment()
  load(f, envir=this)
  res = get(this$var)
  rm(this)
  res
}

printMem = function(go){
  if(go){
    print(gc(reset = T))
  }
}

cat("\n")
args = commandArgs(trailingOnly=T)

spec = matrix(c("<names-file>", "Full path to a tab-separated file with sample names (1st column) and full paths to input Rds files (2nd column)", 
                "<output-prefix>", "Output file names prefix (can contain path to folders)"),  byrow=T, ncol=2)
p = arg_parser("Generate a peak matrix and a sample tree from CHiCAGO output Rda/Rds files.", name="Rscript makePeakMatrix.R")
p = add_argument(p, arg=spec[,1], help=spec[,2])

p = add_argument(p, arg="--scorecol", help = "Column name for the scores", default = "score")
p = add_argument(p, arg="--cutoff", help = "Score cutoff to use", default = 5, type = "numeric")
p = add_argument(p, arg="--lessthan", help = "Pick interactions with scorecol *below* the cutoff rather than above", flag = T)

p = add_argument(p, arg="--fetchcol", help = "Column to fetch; i.e. the information that will end up in the final peak matrix. By default, the same as scorecol. If different,
the --twopass mode will be enforced (unless --peaklist is used)", default = NA)

p = add_argument(p, arg="--maxdist", help = "Max distance from bait to include into the peak matrix and clustering", 
                 default = NA)
p = add_argument(p, arg="--notrans", help = "Exclude trans-interactions", flag = T)

p = add_argument(p, arg="--vanilla", 
                 help="The input RDa/RDS images contain only the table data frames and not Chicago objects", 
                 flag=T)
p = add_argument(p, arg="--digestmap", 
                 "Full path to digest map file; will override settings from ChicagoData even if provided. Required for --vanilla", 
                 default=NA) 
p = add_argument(p, arg="--baitmap", 
                 "Full path to bait map ID file; will override settings from ChicagoData even if provided. Required for --vanilla", 
                 default=NA) 

p = add_argument(p, arg="--twopass", 
                 help="Should the list of significant interactions be generated first (saves memory, but requires two passes of reading the input", 
                 flag=T)
p = add_argument(p, arg="--peaklist", 
                 help="Equivalent to the two-pass mode, but start from a predefined peak list (such as the one generated by the first pass of the two-pass mode", default=NA)

p = add_argument(p, arg="--rda", help="Load from an RDa archive rather than the default Rds", flag=T)
p = add_argument(p, arg="--var", help="The name of the variable containing the chicagoData object or the peak data frame in the RDa images", default="x")

p = add_argument(p, arg="--clustmethod", help = "The clustering method to use (average/ward.D2/complete)", default = "average")
p = add_argument(p, arg="--clustsubset", help = "Number of interactions to randomly subset for clustering (full dataset used if total number of interactions in the peak matrix is below this number", default = 1000000L, type = "numeric")

p = add_argument(p, arg="--print-memory", help = "Print memory info at each step", flag=T)


opts = parse_args(p, args)

message("Loading libraries...\n")

library(data.table)
library(matrixStats)
library(cluster)
library(Hmisc)

### argparser read-in ###

if(packageVersion("argparser") < 0.4)
{
  names(opts) <- gsub("-", "_", names(opts))
}

namesfile = opts[["<names_file>"]]
prefix = opts[["<output_prefix>"]]

cutoff = as.numeric(opts[["cutoff"]])
lessThanCutoff = opts[["lessthan"]]

chicagoData = !opts[["vanilla"]] # sic!
rmapfile = opts[["digestmap"]]
baitmapfile = opts[["baitmap"]]

maxdist = as.numeric(opts[["maxdist"]])
scorecol = opts[["scorecol"]]
noTrans = opts[["notrans"]]

twoPass = opts[["twopass"]]
if(twoPass){
  message("twoPass mode is on")
}

peaklistfile  = opts[["peaklist"]]
if(!is.na(peaklistfile)){
  message(paste("Using peaklistfile", peaklistfile))
}

fetchcol = opts[["fetchcol"]]
if(is.na(fetchcol)) {
  fetchcol <- scorecol
}else{
  if ((!twoPass & is.na(peaklistfile)) & (fetchcol != scorecol)){
    message("Fetchcol is different from scorecol, therefore the twoPass mode is switched on\n")
    twoPass <- TRUE
  }
}

clMethod = opts[["clustmethod"]]
sampsize = as.numeric(opts[["clustsubset"]])

rds = !opts[["rda"]]
var = opts[["var"]]

shouldPrintMem = opts[["print_memory"]]

if(rds & var!="x"){ # if var has been changed from default
  cat("Warning: var name redefined while the --rds option is used, for which it's irrelevant.\n") 
}  
if(twoPass & !is.na(peaklistfile)){
  stop("The specified options --twopass or --peaklist are mutually exclusive.\n")  
}

if(!chicagoData & (is.na(baitmapfile) | is.na(rmapfile))){
  stop("When --vanilla data frame objects are used instead of chicagoData objects, --baitmap and --digestmap files need to be specified.\n")  
}

if (!is.na(baitmapfile)){ # check straight away if possible so not to waste people's time
  if(!file.exists(baitmapfile)){
    stop(paste("Bait map file", baitmapfile, "not found\n"))
  }
  if(!file.exists(rmapfile)){
    stop(paste("Digest map file", rmapfile, "not found\n"))
  }
}

if(lessThanCutoff){
  cat("Will pick interactions with scores *below* the cutoff\n\n")
}

input = read.table(namesfile,stringsAsFactors = F)
names(input) = c("name", "file")

for(nm in input[,"name"]){
  if (!is_valid_variable_name(nm)){
    stop("For convenience of using the resulting data table, sample names should follow the naming rules for valid R variables. Please rename them in the names file and restart makePeakMatrix.\n")
  }
}

sel = data.table(baitID=numeric(0), otherEndID=numeric(0))
if(twoPass){
  cat("Creating a list of significant interactions in at least one sample...\n")
  for(i in 1:nrow(input)){
    f = input[i,"file"]
    
    cat("\tLoading", f, "...\n")
    if (rds){
      x = readRDS(f)
    }
    else{
      x = loadFromRDa(f, var)
    }
    
    if (chicagoData){
      x = x@x
    }
    else{
      setDT(x)          
    }
    
    cat("\t\tFiltering and adding to the list...\n")  
    cat("\t\t\tTotal:", nrow(x), "interactions\n")   
       
    if (lessThanCutoff){
        x = x[get(scorecol)<=cutoff]
    }
    else{
      x = x[get(scorecol)>=cutoff]  
    }
    cat("\t\t\tAfter filtering by score:", nrow(x), "interactions\n")

    if(noTrans){
      x = x[is.na(distSign)==F]
      cat("\t\t\tAfter filtering trans-interactions:", nrow(x), "interactions\n")
    }
    
    if (!is.na(maxdist)){
      x = x[abs(distSign)<=maxdist]
      cat("\t\t\tAfter filtering by maxdist:", nrow(x), "interactions\n")
    }
    
    sel = rbindlist(list(sel, x[, c("baitID", "otherEndID"), with=F]))
    cat("\t\t\tTotal peaks after rbindlist(sel, x):", nrow(sel), "\n")

    setkey(sel, baitID, otherEndID)
    sel = unique(sel)
    cat("\t\t\tTotal peaks after unique(sel):", nrow(sel), "\n")
  }
  
  printMem(shouldPrintMem)
  rm(x)
  printMem(shouldPrintMem)
  
  cat("Saving the peak list as", paste0(prefix,"_peaklist.txt"), "...\n")
  
  write.table(sel, paste0(prefix,"_peaklist.txt"), row.names=F, col.names=T, quote=F, sep="\t")
  
  cat("\nReloading samples...\n")
}

if (!is.na(peaklistfile)){
  sel = fread(peaklistfile)
  if((!"baitID" %in% names(sel)) | (!"otherEndID" %in% names(sel))){
  message("Warning! Expecting the names of the peaklist to be baitID and otherEndID. Since it's not the case, will use the first two columns of the peaklist as such")
  setnames(sel, 1:2, c("baitID", "otherEndID"))
  }
  setkey(sel, baitID, otherEndID)
}

message("Loading data...\n")
data = vector("list")
for (i in 1:nrow(input)){
  f = input[i,"file"]    
  
  cat("\tLoading", f, "...\n")
  if (rds){
    x = readRDS(f)
  }
  else{
    x = loadFromRDa(f, var)
  }
  
  if (chicagoData){
    # currently not checking for consistency of baitmaps/rmaps between objects
    if (is.na(baitmapfile)){
      baitmapfile = x@settings[["baitmapfile"]]
      if(!file.exists(baitmapfile)){
        stop(paste("Bait map file", baitmapfile, "not found\n"))
      }      
    }
    if (is.na(rmapfile)){
      rmapfile = x@settings[["rmapfile"]]
      if(!file.exists(rmapfile)){
        stop(paste("Digest map file", rmapfile, "not found\n"))
      }
    }
    x = x@x
  }
  else{
    setDT(x)    
  }
  
  cat("\t\tFiltering and processing...\n")

  cat("\t\t\tTotal interactions:", nrow(x), "\n")

  if(twoPass | !is.na(peaklistfile)){
    setkey(x, baitID, otherEndID)  
    x = x[sel]    
    cat("\t\t\tAfter x[sel]:", nrow(x), "interactions\n")
  }
  else{
    if(noTrans){
      x = x[is.na(distSign)==F]
      cat("\t\t\tAfter filtering out trans-interactions:", nrow(x), "\n")
    }
    if (!is.na(maxdist)){
      x = x[abs(distSign)<=maxdist]
      cat("\t\t\tAfter filtering by maxdist:", nrow(x), "\n")
    }    
  }
  
  cat("\t\t\tBefore data[[name]] = x:", nrow(x), "\n")

  name = input[i, "name"]
  data[[name]] = x[, c("baitID", "otherEndID", fetchcol), with=F]
  setnames(data[[name]], fetchcol, name)
  setkey(data[[name]], baitID, otherEndID)
  
  printMem(shouldPrintMem)
  
}

rm(x)
printMem(shouldPrintMem)

cat("\nMerging...\n")

z = Reduce(function(x,y) merge(x,y,all=TRUE), data)

printMem(shouldPrintMem)
rm(data)
printMem(shouldPrintMem)


if(!twoPass & is.na(peaklistfile)){
  scoreCols = names(z)[3:ncol(z)]
  if (lessThanCutoff){
    cat("Retaining only interactions below the score cutoff", cutoff, "in at least one sample...\n")
    z[, rmin:=eval(parse(text=paste0("pmin(", paste0(scoreCols, collapse=","),", na.rm=T)")))]  
    z = z[rmin<=cutoff]
  }else{
    cat("Retaining only interactions exceeding score cutoff", cutoff, "in at least one sample...\n")
    z[, rmax:=eval(parse(text=paste0("pmax(", paste0(scoreCols, collapse=","),", na.rm=T)")))]  
    z = z[rmax>=cutoff]
  }
}

cat("Replacing NAs with zeros...\n")
for (i in 3:ncol(z)){
  set(z, which(is.na(z[[i]])), i, 0)
}

cat("Adding bait coordinates and annotation...\n")
bm = fread(baitmapfile)
setnames(bm, c("V1", "V2", "V3", "V4", "V5"), c("baitChr", "baitStart", "baitEnd", "baitID", "baitName"))
setkey(z, baitID)
setkey(bm, baitID)
z = merge(z, bm)

cat("Adding otherEnd coordinates...\n")
setkey(z, otherEndID)
rm = fread(rmapfile)
setnames(rm, c("V1", "V2", "V3", "V4"), c("oeChr", "oeStart", "oeEnd", "otherEndID"))
setkey(rm, otherEndID)
z = merge(z, rm)

cat("Annotating bait2bait interations...\n")
#setkey(z, otherEndID) - still remains one from the above code
setnames(bm, c("baitID", "baitName"), c("otherEndID", "otherEndName")) # sic!
setkey(bm, otherEndID)
z = merge(z, bm[, c("otherEndID", "otherEndName"), with=F], all.x=T, all.y=F)
set(z, which(is.na(z$otherEndName)), "otherEndName", ".")

cat("Adding distances and sorting...\n")

z[, dist := NA_real_]
z[baitChr==oeChr, dist := ceiling(oeStart+(oeEnd-oeStart)/2-(baitStart+(baitEnd-baitStart)/2))]

setnames(z, "otherEndID", "oeID")
setnames(z, "otherEndName", "oeName")
setDF(z)
z = z[, c("baitChr", "baitStart", "baitEnd", "baitID", "baitName", "oeChr", "oeStart", "oeEnd", "oeID", "oeName", "dist", input[,"name"])]

z = z[order(z$baitChr, z$baitStart, z$oeChr, z$oeStart), ]

rdsname = paste0(prefix, ".Rds")
cat(paste0("Saving the result image as ", rdsname, "...\n"))
saveRDS(z, file=rdsname)

txtname = paste0(prefix, ".txt")
cat(paste0("Writing out the result as ", txtname, "...\n"))
write.table(z, txtname, quote = F, sep = "\t", col.names = T, row.names=F)

if (nrow(input)>2){
  if (sampsize>nrow(z)){
    cat("Using the whole data matrix for clustering\n")
    zsamp = z
  }
  else{
    cat("Clustering samples based on", sampsize,  "random interactions...\n")
    zsamp = z[sample(1:nrow(z), sampsize),]    
  }
  d = dist(t(zsamp[,12:ncol(zsamp)]))
  h = hclust(d, method=clMethod)
  
  pdfname = paste0(prefix, "_tree.pdf")
  cat(paste0("Saving the sample dendrogram as ", pdfname, "...\n"))
  pdf(pdfname, width=20, height=10)
  plot(h)
  dev.off()
  
  #cat("Using binary signals ( cutoff =", cutoff, ")...\n")
  #zsbin = apply(zsamp[, 12:ncol(zsamp)],1,function(x){x[x<cutoff]=0; x[x>=cutoff];x})
  #db = daisy(t(zsbin), metric="gower")
  #hb = hclust(db, method=clMethod)
  #pdfname = paste0(prefix, "_tree_binary.pdf")
  #cat(paste0("Saving the sample dendrogram as ", pdfname, "...\n"))
  #pdf(pdfname, width=20, height=10)
  #plot(hb)
  #dev.off()
}else{
  cat("Clustering not performed as n<=2\n")
}
cat("Done!\n")
