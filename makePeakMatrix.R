library(data.table)
library(matrixStats)
library(cluster)
library(argparser)
library(Hmisc)

### A great function from http://www.r-bloggers.com/testing-for-valid-variable-names/
is_valid_variable_name = function(x, allow_reserved = TRUE, unique = FALSE)
{
  ok = TRUE
  max_name_length <- if(getRversion() < "2.13.0") 256L else 10000L
  if(!allow_reserved){
    ok[x == "..."] <- FALSE
    ok[grepl("^\\.{2}[[:digit:]]+$", x)] <- FALSE
  }
  ok[x != make.names(x, unique = unique)] <- FALSE
  ok
}

cat("\n")
args = commandArgs(trailingOnly=T)
spec = matrix(c("<names-file>", "Full path to a tab-separated file with sample names (1st column) and full paths to input Rda files (2nd column)", 
                "<output-prefix>", "Output file names prefix (can contain path to folders)", 
                "<digest-map>", "Full path to digest map file", 
                "<bait-map>", "Full path to bait map ID file"),  byrow=T, ncol=2)
p = arg.parser("Generate a peak matrix and a sample tree from CHiCAGO output Rda files.", name="Rscript makePeakMatrix.R")
p = add.argument(p, arg=spec[,1], help=spec[,2])
p = add.argument(p, arg="--cutoff", help = "Score cutoff to use", default = 5, type = "numeric")
p = add.argument(p, arg="--lessthan", help = "Pick interactions with scorecol *below* the cutoff rather than above", flag = T)
p = add.argument(p, arg="--subset", help = "Number of interactions to randomly subset for clustering", default = 100000)
p = add.argument(p, arg="--maxdist", help = "Max distance from bait to include into the peak matrix and clustering", default = NA, type="numeric")
p = add.argument(p, arg="--scorecol", help = "Column name for the scores", default = "score")
p = add.argument(p, arg="--clustmethod", help = "The clustering method to use (average/ward.D2/complete)", default = "average")
p = add.argument(p, arg="--notrans", help = "Exclude trans-interactions", flag = T)
p = add.argument(p, arg="--twopass", help="Should the list of significant interactions be generated first (saves memory, but requires two passes of reading the input", flag=T)
p = add.argument(p, arg="--peaklist", help="Equivalent to the two-pass mode, but start from a predefined peak list (such as the one generated by the first pass of the two-pass mode", default=NA, type="numeric")
opts = parse.args(p, args)

namesfile = opts[["<names-file>"]]
prefix = opts[["<output-prefix>"]]
cutoff = opts[["cutoff"]]
sampsize = opts[["subset"]]
rmapfile = opts[["<digest-map>"]]
baitmapfile = opts[["<bait-map>"]]
maxdist = opts[["maxdist"]]
scorecol = opts[["scorecol"]]
clMethod = opts[["clustmethod"]]
noTrans = opts[["notrans"]]
twoPass = opts[["twopass"]]
peaklistfile  = opts[["peaklist"]]
lessThanCutoff = opts[["lessthan"]]

if(twoPass & !is.na(peaklistfile)){
  stop("The specified options --twopass or --peaklist are mutually exclusive.\n")  
}

if(lessThanCutoff){
  cat("Will pick interactions with scores *below* the cutoff\n\n")
}

bm = fread(baitmapfile)
setnames(bm, c("V1", "V2", "V3", "V4", "V5"), c("baitChr", "baitStart", "baitEnd", "baitID", "baitName"))

input = read.table(namesfile,stringsAsFactors = F)
names(input) = c("name", "file")

for(nm in input[,"name"]){
  if (!is_valid_variable_name(nm)){
    stop("For convenience of using the resulting data table, sample names should follow the naming rules for valid R variables. Please rename them in the names file and restart makePeakMatrix.\n")
  }
}

sel = data.table(baitID=numeric(0), otherEndID=numeric(0))
if(twoPass){
  cat("Creating a list of significant interactions in at least one sample...\n")
  for(i in 1:nrow(input)){
    f = input[i,"file"]
    
    cat("\tLoading", f, "...\n")
    load(f)
  
    cat("\t\tFiltering and adding to the list...\n")  
    setDT(x)
    cat("\t\t\tTotal:", nrow(x), "interactions\n")   
       
    if (lessThanCutoff){
        x = x[get(scorecol)<=cutoff]
    }else{
    	x = x[get(scorecol)>=cutoff]  
    }
    cat("\t\t\tAfter filtering by score:", nrow(x), "interactions\n")

    if(noTrans){
      x = x[is.na(distSign)==F]
      cat("\t\t\tAfter filtering trans-interactions:", nrow(x), "interactions\n")
    }
    
    if (!is.na(maxdist)){
      x = x[abs(distSign)<=maxdist]
      cat("\t\t\tAfter filtering by maxdist:", nrow(x), "interactions\n")
    }
    
    sel = rbindlist(list(sel, x[, c("baitID", "otherEndID"), with=F]))
    cat("\t\t\tTotal peaks after rbindlist(sel, x):", nrow(sel), "\n")

    setkey(sel, baitID, otherEndID)
    sel = unique(sel)
    cat("\t\t\tTotal peaks after unique(sel):", nrow(sel), "\n")
  }
  
  print (gc(reset = T))
  rm(x)
  print (gc(reset = T))
  
  cat("Saving the peak list as", paste0(prefix,"_peaklist.txt"), "...\n")
  
  write.table(sel, paste0(prefix,"_peaklist.txt"), row.names=F, col.names=T, quote=F, sep="\t")
  
  cat("\nReloading samples...\n")
}

if (!is.na(peaklistfile)){
  sel = fread(peaklistfile)
}


data = vector("list")
for (i in 1:nrow(input)){
  f = input[i,"file"]    
  
  cat("\tLoading", f, "...\n")
  load(f)
  
  cat("\t\tFiltering and processing...\n")

  setDT(x)
  cat("\t\t\tTotal interactions:", nrow(x), "\n")

  if(twoPass | !is.na(peaklistfile)){
    setkey(x, baitID, otherEndID)  
    x = x[sel]    
    cat("\t\t\tAfter x[sel]:", nrow(x), "interactions\n")
  }
  else{
    if (lessThanCutoff){
        x = x[get(scorecol)<=cutoff]
    }else{
        x = x[get(scorecol)>=cutoff]
    }
    cat("\t\t\tAfter subsetting by score:", nrow(x), "\n")

    if(noTrans){
      x = x[is.na(distSign)==F]
      cat("\t\t\tAfter filtering out trans-interactions:", nrow(x), "\n")
    }
    
    if (!is.na(maxdist)){
      x = x[abs(distSign)<=maxdist]
      cat("\t\t\tAfter filtering by maxdist:", nrow(x), "\n")
    }    
  }
  
  cat("\t\t\tBefore data[[name]] = x:", nrow(x), "\n")

  name = input[i, "name"]
  data[[name]] = x[, c("baitID", "otherEndID", scorecol), with=F]
  setnames(data[[name]], scorecol, name)
  setkey(data[[name]], baitID, otherEndID)
  
  print(gc(reset = T))
}

rm(x)
print(gc(reset = T))

cat("\nMerging...\n")

z = Reduce(function(x,y) merge(x,y,all=TRUE), data)

print(gc(reset = T))
rm(data)
print(gc(reset = T))

if(!twoPass){
  cat("Retaining only interactions exceeding score cutoff", cutoff, "in at least one sample...\n")
  scoreCols = names(z)[3:ncol(z)]
  z[, rmax:=eval(parse(text=paste0("pmax(", paste0(scoreCols, collapse=","),", na.rm=T)")))]
  z = z[rmax>=cutoff]
}

cat("Replacing NAs with zeros...\n")
for (i in 3:ncol(z)){
  set(z, which(is.na(z[[i]])), i, 0)
}

cat("Adding bait coordinates and annotation...\n")
setkey(z, baitID)

#baitNames = gsub("\\-\\d{3}", "", bm$baitName) # remove transcript IDs
#baitNamesList = strsplit(baitNames, ",")
#baitNamesDedup = sapply(baitNamesList, function(x)paste(x[!duplicated(x)], collapse="," )) # put back together without duplicates
#bm$baitName = baitNamesDedup

setkey(bm, baitID)
z = merge(z, bm)

cat("Adding otherEnd coordinates...\n")
setkey(z, otherEndID)
rm = fread(rmapfile)
setnames(rm, c("V1", "V2", "V3", "V4"), c("oeChr", "oeStart", "oeEnd", "otherEndID"))
setkey(rm, otherEndID)
z = merge(z, rm)

cat("Annotating bait2bait interations...\n")
#setkey(z, otherEndID) - still remains one from the above code
setnames(bm, c("baitID", "baitName"), c("otherEndID", "otherEndName")) # sic!
setkey(bm, otherEndID)
z = merge(z, bm[, c("otherEndID", "otherEndName"), with=F], all.x=T, all.y=F)
set(z, which(is.na(z$otherEndName)), "otherEndName", ".")

cat("Adding distances and sorting...\n")

z[, dist := NA_real_]
z[baitChr==oeChr, dist := ceiling(oeStart+(oeEnd-oeStart)/2-(baitStart+(baitEnd-baitStart)/2))]

setnames(z, "otherEndID", "oeID")
setnames(z, "otherEndName", "oeName")
setDF(z)
z = z[, c("baitChr", "baitStart", "baitEnd", "baitID", "baitName", "oeChr", "oeStart", "oeEnd", "oeID", "oeName", "dist", input[,"name"])]

z = z[order(z$baitChr, z$baitStart, z$oeChr, z$oeStart), ]

rdsname = paste0(prefix, ".Rds")
cat(paste0("Saving the result image as ", rdsname, "...\n"))
saveRDS(z, file=rdsname)

txtname = paste0(prefix, ".txt")
cat(paste0("Writing out the result as ", txtname, "...\n"))
write.table(z, txtname, quote = F, sep = "\t", col.names = T, row.names=F)

if (nrow(input)>2){
  cat("Clustering samples based on", sampsize,  "random interactions...\n")
  if (sampsize>nrow(z)){
    cat(paste0("Warning: requested random subset size for clustering (", sampsize, ") was larger than the peak matrix size", nrow(z), 
". Using the whole matrix\n"))
    zsamp = z
  }
  else{
    zsamp = z[sample(1:nrow(z), sampsize),]    
  }
  d = dist(t(zsamp[,12:ncol(zsamp)]))
  h = hclust(d, method=clMethod)
  
  pdfname = paste0(prefix, "_tree.pdf")
  cat(paste0("Saving the sample dendrogram as ", pdfname, "...\n"))
  pdf(pdfname, width=20, height=10)
  plot(h)
  dev.off()
  
  #cat("Using binary signals ( cutoff =", cutoff, ")...\n")
  #zsbin = apply(zsamp[, 12:ncol(zsamp)],1,function(x){x[x<cutoff]=0; x[x>=cutoff];x})
  #db = daisy(t(zsbin), metric="gower")
  #hb = hclust(db, method=clMethod)
  #pdfname = paste0(prefix, "_tree_binary.pdf")
  #cat(paste0("Saving the sample dendrogram as ", pdfname, "...\n"))
  #pdf(pdfname, width=20, height=10)
  #plot(hb)
  #dev.off()
}else{
  cat("Clustering not performed as n<=2\n")
}
cat("Done!\n")
